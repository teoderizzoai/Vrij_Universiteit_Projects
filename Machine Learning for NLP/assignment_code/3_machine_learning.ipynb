{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\teode\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\teode\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump\n",
    "from collections import Counter\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\" Convert Treebank tags to WordNet tags \"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to NOUN\n",
    "\n",
    "def extract_features_and_labels(file_path, include_embeddings=True):\n",
    "    data = []\n",
    "    targets = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_vectors = KeyedVectors.load_word2vec_format(\"embeddings/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            components = line.rstrip('\\n').split()\n",
    "            if len(components) == 10:\n",
    "                token, preceding_token, next_token, lemma, capitalization, word_shape, word_length, pos_tag, chunk_label, gold_label = components\n",
    "\n",
    "                # Prepare embeddings only if needed\n",
    "                embedding_features = {}\n",
    "                if include_embeddings:\n",
    "                    # Get embedding if available, else use a zero vector\n",
    "                    embedding = word_vectors[token] if token in word_vectors else [0]*300\n",
    "                    embedding_features = {f'emb_{i}': emb for i, emb in enumerate(embedding)}\n",
    "\n",
    "                feature_dict = {\n",
    "                    'token': token,\n",
    "                    'preceding_token': preceding_token,\n",
    "                    'next_token': next_token,\n",
    "                    'lemma': lemma,\n",
    "                    'capitalization': capitalization,\n",
    "                    'word_shape': word_shape,\n",
    "                    'word_length': str(word_length),\n",
    "                    'pos_tag': pos_tag,\n",
    "                    'chunk_label': chunk_label\n",
    "                }\n",
    "\n",
    "                # Add embedding features if they are to be included\n",
    "                feature_dict.update(embedding_features)\n",
    "\n",
    "                data.append(feature_dict)\n",
    "                targets.append(gold_label)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "def create_classifier(train_features, train_targets, model_name):\n",
    "    vec = DictVectorizer()\n",
    "    features_vectorized = vec.fit_transform(train_features)\n",
    "\n",
    "    if model_name == 'logreg':\n",
    "        model = LogisticRegression(max_iter=10000, C=0.1)\n",
    "    elif model_name == 'NB':\n",
    "        model = MultinomialNB()\n",
    "    elif model_name == 'SVM':\n",
    "        model = SVC(probability=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_name}\")\n",
    "\n",
    "    model.fit(features_vectorized, train_targets)\n",
    "    return model, vec\n",
    "\n",
    "def classify_and_evaluate(model, vec, test_features, test_labels):\n",
    "    features_vectorized = vec.transform(test_features)\n",
    "    predictions = model.predict(features_vectorized)\n",
    "    print(classification_report(test_labels, predictions))\n",
    "    return predictions\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"data/pre.conll2003.train.conll\"\n",
    "dev_file = \"data/pre.conll2003.dev.conll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting train\n",
      "extracting dev\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels from the training and development files\n",
    "print(\"extracting train\")\n",
    "train_features, train_labels = extract_features_and_labels(training_file, include_embeddings=True)\n",
    "print(\"extracting dev\")\n",
    "dev_features, dev_labels = extract_features_and_labels(dev_file, include_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.81      0.80      0.80      1827\n",
      "      B-MISC       0.83      0.68      0.75       914\n",
      "       B-ORG       0.69      0.65      0.67      1335\n",
      "       B-PER       0.78      0.77      0.77      1818\n",
      "       I-LOC       0.81      0.61      0.70       257\n",
      "      I-MISC       0.92      0.46      0.61       342\n",
      "       I-ORG       0.71      0.58      0.64       748\n",
      "       I-PER       0.65      0.94      0.77      1294\n",
      "           O       0.95      0.97      0.96      5209\n",
      "\n",
      "    accuracy                           0.83     13744\n",
      "   macro avg       0.79      0.72      0.74     13744\n",
      "weighted avg       0.83      0.83      0.82     13744\n",
      "\n",
      "Running NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.69      0.89      0.78      1827\n",
      "      B-MISC       0.88      0.75      0.81       914\n",
      "       B-ORG       0.67      0.77      0.72      1335\n",
      "       B-PER       0.83      0.79      0.81      1818\n",
      "       I-LOC       0.88      0.43      0.58       257\n",
      "      I-MISC       0.94      0.39      0.55       342\n",
      "       I-ORG       0.73      0.57      0.64       748\n",
      "       I-PER       0.88      0.84      0.86      1294\n",
      "           O       0.95      0.96      0.96      5209\n",
      "\n",
      "    accuracy                           0.84     13744\n",
      "   macro avg       0.83      0.71      0.74     13744\n",
      "weighted avg       0.85      0.84      0.84     13744\n",
      "\n",
      "Running SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.87      0.81      0.84      1827\n",
      "      B-MISC       0.84      0.73      0.78       914\n",
      "       B-ORG       0.75      0.68      0.71      1335\n",
      "       B-PER       0.81      0.81      0.81      1818\n",
      "       I-LOC       0.81      0.68      0.74       257\n",
      "      I-MISC       0.89      0.57      0.70       342\n",
      "       I-ORG       0.71      0.63      0.67       748\n",
      "       I-PER       0.66      0.95      0.78      1294\n",
      "           O       0.97      0.98      0.97      5209\n",
      "\n",
      "    accuracy                           0.85     13744\n",
      "   macro avg       0.81      0.76      0.78     13744\n",
      "weighted avg       0.86      0.85      0.85     13744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "for model_name in ['logreg', 'NB', 'SVM']:\n",
    "    print(f\"Running {model_name}\")\n",
    "    model, vec = create_classifier(train_features, train_labels, model_name)\n",
    "    predictions = classify_and_evaluate(model, vec, dev_features, dev_labels)\n",
    "\n",
    "    # Save the model and vectorizer\n",
    "    model_filename = f\"models/{model_name}_model.joblib\"\n",
    "    vec_filename = f\"models/{model_name}_vectorizer.joblib\"\n",
    "    dump(model, model_filename)\n",
    "    dump(vec, vec_filename)\n",
    "\n",
    "    # Output predictions\n",
    "    output_file = f\"data/output_{model_name}.conll\"\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for feature, prediction in zip(dev_features, predictions):\n",
    "            outfile.write(f\"{feature}\\t{prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.89      0.87      0.88      1827\n",
      "      B-MISC       0.87      0.81      0.84       914\n",
      "       B-ORG       0.78      0.79      0.78      1335\n",
      "       B-PER       0.90      0.89      0.89      1818\n",
      "       I-LOC       0.78      0.71      0.74       257\n",
      "      I-MISC       0.83      0.61      0.70       342\n",
      "       I-ORG       0.72      0.63      0.67       748\n",
      "       I-PER       0.83      0.92      0.87      1294\n",
      "           O       0.96      0.99      0.98      5209\n",
      "\n",
      "    accuracy                           0.89     13744\n",
      "   macro avg       0.84      0.80      0.82     13744\n",
      "weighted avg       0.89      0.89      0.89     13744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "for model_name in ['SVM']:\n",
    "    print(f\"Running {model_name}\")\n",
    "    model, vec = create_classifier(train_features, train_labels, model_name)\n",
    "    predictions = classify_and_evaluate(model, vec, dev_features, dev_labels)\n",
    "\n",
    "    # Save the model and vectorizer\n",
    "    model_filename = f\"models/{model_name}_model.joblib\"\n",
    "    vec_filename = f\"models/{model_name}_vectorizer.joblib\"\n",
    "    dump(model, model_filename)\n",
    "    dump(vec, vec_filename)\n",
    "\n",
    "    # Output predictions\n",
    "    output_file = f\"data/output_{model_name}_embedded.conll\"\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for feature, prediction in zip(dev_features, predictions):\n",
    "            outfile.write(f\"{feature}\\t{prediction}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
