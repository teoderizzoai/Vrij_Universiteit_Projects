{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\teode\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\teode\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump\n",
    "from collections import Counter\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\" Convert Treebank tags to WordNet tags \"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to NOUN\n",
    "\n",
    "def extract_features_and_labels(file_path, include_embeddings=True):\n",
    "    data = []\n",
    "    targets = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_vectors = KeyedVectors.load_word2vec_format(\"embeddings/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            components = line.rstrip('\\n').split()\n",
    "            if len(components) == 10:\n",
    "                token, preceding_token, next_token, lemma, capitalization, word_shape, word_length, pos_tag, chunk_label, gold_label = components\n",
    "\n",
    "                # Prepare embeddings only if needed\n",
    "                embedding_features = {}\n",
    "                if include_embeddings:\n",
    "                    # Get embedding if available, else use a zero vector\n",
    "                    embedding = word_vectors[token] if token in word_vectors else [0]*300\n",
    "                    embedding_features = {f'emb_{i}': emb for i, emb in enumerate(embedding)}\n",
    "\n",
    "                feature_dict = {\n",
    "                    'token': token,\n",
    "                    'preceding_token': preceding_token,\n",
    "                    'next_token': next_token,\n",
    "                    'lemma': lemma,\n",
    "                    'capitalization': capitalization,\n",
    "                    'word_shape': word_shape,\n",
    "                    'word_length': str(word_length),\n",
    "                    'pos_tag': pos_tag,\n",
    "                    'chunk_label': chunk_label\n",
    "                }\n",
    "\n",
    "                # Add embedding features if they are to be included\n",
    "                feature_dict.update(embedding_features)\n",
    "\n",
    "                data.append(feature_dict)\n",
    "                targets.append(gold_label)\n",
    "\n",
    "    return data, targets\n",
    "\n",
    "def create_classifier(train_features, train_targets, parameters):\n",
    "    vec = DictVectorizer()\n",
    "    features_vectorized = vec.fit_transform(train_features)\n",
    "    model = SVC(parameters)\n",
    "    return model, vec\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def classify_and_evaluate(model, vec, features, labels):\n",
    "    # Transform the features using the vectorizer\n",
    "    features_vectorized = vec.transform(features)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(features_vectorized)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(labels, predictions, average='weighted')  # or choose another appropriate average method\n",
    "    return f1\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def create_smaller_dataset(input_file, output_file, num_samples):\n",
    "    # Initialize an empty list to store valid lines\n",
    "    valid_lines = []\n",
    "\n",
    "    # Read the CoNLL-2003 file line by line and filter valid lines\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) == 10:  # Expecting 10 fields\n",
    "                valid_lines.append(line)\n",
    "\n",
    "    # Shuffle the valid lines\n",
    "    random.shuffle(valid_lines)\n",
    "\n",
    "    # Select the specified number of samples\n",
    "    smaller_lines = valid_lines[:num_samples]\n",
    "\n",
    "    # Save the smaller dataset to a new file\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.writelines(smaller_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_file = 'data/pre.conll2003.train.conll'\n",
    "output_file = 'data/pre.conll2003.train_small.conll'\n",
    "num_samples = 10000\n",
    "\n",
    "\n",
    "create_smaller_dataset(input_file, output_file, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_file = 'data/pre.conll2003.dev.conll'\n",
    "output_file = 'data/pre.conll2003.dev_small.conll'\n",
    "num_samples = 10000\n",
    "\n",
    "\n",
    "create_smaller_dataset(input_file, output_file, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file = \"data/pre.conll2003.train_small.conll\"\n",
    "dev_file = \"data/pre.conll2003.dev_small.conll\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting train\n",
      "extracting dev\n"
     ]
    }
   ],
   "source": [
    "# Extract features and labels from the training and development files\n",
    "print(\"extracting train\")\n",
    "train_features, train_labels = extract_features_and_labels(training_file, include_embeddings=False)\n",
    "print(\"extracting dev\")\n",
    "dev_features, dev_labels = extract_features_and_labels(dev_file, include_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "score: 0.7413394765488079\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "score: 0.7413394765488079\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "score: 0.453911167206041\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "score: 0.7413394765488079\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "score: 0.5518822070916575\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "score: 0.5329087323959395\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 1, 'kernel': 'linear'}\n",
      "score: 0.7413394765488079\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 1, 'kernel': 'rbf'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 0.1, 'class_weight': None, 'gamma': 1, 'kernel': 'poly'}\n",
      "score: 0.7968378580470087\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'linear'}\n",
      "score: 0.7361957539253499\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "score: 0.21336581818181818\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'linear'}\n",
      "score: 0.7361957539253499\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "score: 0.5707597159032533\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'linear'}\n",
      "score: 0.7361957539253499\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "score: 0.620694024912764\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'poly'}\n",
      "score: 0.622987414570578\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'linear'}\n",
      "score: 0.7361957539253499\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf'}\n",
      "score: 0.22072739319745063\n",
      "Running with parameters: {'C': 0.1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'poly'}\n",
      "score: 0.7949671106688744\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "score: 0.8247861080766017\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "score: 0.4555981635288275\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "score: 0.8247861080766017\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "score: 0.5705428044801918\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "score: 0.8247861080766017\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "score: 0.7382652612950666\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "score: 0.7341684588331375\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 1, 'kernel': 'linear'}\n",
      "score: 0.8247861080766017\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 1, 'kernel': 'rbf'}\n",
      "score: 0.41700770233585827\n",
      "Running with parameters: {'C': 1, 'class_weight': None, 'gamma': 1, 'kernel': 'poly'}\n",
      "score: 0.7968378580470087\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'linear'}\n",
      "score: 0.8282148973381362\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "score: 0.5194371319263495\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'poly'}\n",
      "score: 0.0005039370078740158\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'linear'}\n",
      "score: 0.8282148973381362\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "score: 0.6228593531785939\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'poly'}\n",
      "score: 0.0005039370078740158\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'linear'}\n",
      "score: 0.8282148973381362\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "score: 0.7297848404444037\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'poly'}\n",
      "score: 0.7311958334335571\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'linear'}\n",
      "score: 0.8282148973381362\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf'}\n",
      "score: 0.5866509072352992\n",
      "Running with parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'poly'}\n",
      "score: 0.7949671106688744\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "score: 0.8268647617295949\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "score: 0.5703719545710887\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "score: 0.8268647617295949\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "score: 0.7969007574893218\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "score: 0.8268647617295949\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "score: 0.8097966656749304\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "score: 0.7968378580470087\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 1, 'kernel': 'linear'}\n",
      "score: 0.8268647617295949\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 1, 'kernel': 'rbf'}\n",
      "score: 0.47110815230929026\n",
      "Running with parameters: {'C': 10, 'class_weight': None, 'gamma': 1, 'kernel': 'poly'}\n",
      "score: 0.7968378580470087\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'linear'}\n",
      "score: 0.8259234861857937\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "score: 0.6335979868244096\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'linear'}\n",
      "score: 0.8259234861857937\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "score: 0.7789348098054778\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'linear'}\n",
      "score: 0.8259234861857937\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "score: 0.8097966656749304\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'poly'}\n",
      "score: 0.7968378580470087\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'linear'}\n",
      "score: 0.8259234861857937\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf'}\n",
      "score: 0.47110815230929026\n",
      "Running with parameters: {'C': 10, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'poly'}\n",
      "score: 0.7949671106688744\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "score: 0.818302679788435\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "score: 0.8035366207760146\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "score: 0.21213159797541575\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "score: 0.818302679788435\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "score: 0.823901680608981\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "score: 0.5329087323959395\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "score: 0.818302679788435\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "score: 0.8097966656749304\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "score: 0.7968378580470087\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 1, 'kernel': 'linear'}\n",
      "score: 0.818302679788435\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 1, 'kernel': 'rbf'}\n",
      "score: 0.47110815230929026\n",
      "Running with parameters: {'C': 100, 'class_weight': None, 'gamma': 1, 'kernel': 'poly'}\n",
      "score: 0.7968378580470087\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'linear'}\n",
      "score: 0.8198167667831833\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "score: 0.7796440273059957\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'poly'}\n",
      "score: 0.02653119429590018\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'linear'}\n",
      "score: 0.8198167667831833\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "score: 0.823901680608981\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.01, 'kernel': 'poly'}\n",
      "score: 0.622987414570578\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'linear'}\n",
      "score: 0.8198167667831833\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "score: 0.8088385085395655\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'poly'}\n",
      "score: 0.7949671106688744\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'linear'}\n",
      "score: 0.8198167667831833\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'rbf'}\n",
      "score: 0.47110815230929026\n",
      "Running with parameters: {'C': 100, 'class_weight': 'balanced', 'gamma': 1, 'kernel': 'poly'}\n",
      "score: 0.7949671106688744\n",
      "Best parameters: {'C': 1, 'class_weight': 'balanced', 'gamma': 0.001, 'kernel': 'linear'} with a score of 0.8282148973381362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def create_classifier(features, labels, parameters):\n",
    "    # Vectorize features\n",
    "    vec = DictVectorizer()\n",
    "    vec_features = vec.fit_transform(features)\n",
    "\n",
    "    # Create and train the SVC model\n",
    "    model = SVC(**parameters)\n",
    "    model.fit(vec_features, labels)\n",
    "\n",
    "    return model, vec\n",
    "\n",
    "# Define the parameter grid for SVC\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "\n",
    "feature_list = ['OriginalWord', 'PreviousWord', 'NextWord', 'Lemma', 'Capitalization', \n",
    "                    'WordShape', 'WordLength', 'POS', 'ChunkTag', 'NamedEntityTag']\n",
    "\n",
    "best_score = 0\n",
    "best_parameters = None\n",
    "\n",
    "parameter_combinations = list(ParameterGrid(param_grid))\n",
    "\n",
    "# Iterate over each parameter combination\n",
    "for parameters in parameter_combinations:\n",
    "    print(f\"Running with parameters: {parameters}\")\n",
    "    model, vec = create_classifier(train_features, train_labels, parameters)\n",
    "    score = classify_and_evaluate(model, vec, dev_features, dev_labels)\n",
    "    print(f\"score: {score}\")\n",
    "    # Ensure that 'score' is numeric\n",
    "    if not isinstance(score, (int, float)):\n",
    "        raise ValueError(f\"The returned score is not numeric: {score}\")\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_parameters = parameters\n",
    "\n",
    "print(f\"Best parameters: {best_parameters} with a score of {best_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
